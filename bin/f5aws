#!/usr/bin/python

"""

Chris Mutzel <c.mutzel@f5.com>
Alex Applebaum <a.applebaum@f5.com>

For more information on usage see README.md

"""

import sys
import os
import stat
import argparse
import yaml
import itertools
import re
import json
import ConfigParser

# Augment PYTHONPATH to find Python modules relative to this file path
# This is so that we can find the modules when running from a local checkout
# installed as editable with `pip install -e ...` or `python setup.py develop`
local_module_path = os.path.abspath(
    os.path.join(os.path.dirname(__file__), '..', 'lib')
)
sys.path.append(local_module_path)


import ansible.playbook
import ansible.constants as constants
import ansible.utils.template
from ansible import errors
from ansible import callbacks
from ansible import utils
from ansible.color import ANSIBLE_COLOR, stringc
from ansible.callbacks import display

__version__ = "0.2"
__prog__ = "f5aws"

# set of variables which must be defined in ~/.f5aws
REQUIRED_VARS = ['install_path', 'ssh_key',
  'bigip_rest_user', 'bigip_rest_password',
  'f5_aws_access_key', 'f5_aws_secret_key']

def colorize(lead, num, color):
  """ Print 'lead' = 'num' in 'color' """
  if num != 0 and ANSIBLE_COLOR and color is not None:
    return "%s%s%-15s" % (stringc(lead, color),
        stringc("=", color), stringc(str(num), color))
  else:
      return "%s=%-4s" % (lead, str(num))

def hostcolor(host, stats, color=True):
  if ANSIBLE_COLOR and color:
      if stats['failures'] != 0 or stats['unreachable'] != 0:
          return "%-37s" % stringc(host, 'red')
      elif stats['changed'] != 0:
          return "%-37s" % stringc(host, 'yellow')
      else:
          return "%-37s" % stringc(host, 'green')
  return "%-26s" % host


def convert_str(inStr):
  """
    One of the quirks with ansible is the use of several different 
    object notations, sometimes even one embedded within another...
    This function modifies the string formatting so we can read it 
    in as a variable. 
  """
  l = [i.split('=') for i in inStr.split(' ')]
  res_arr = [i.replace('"','') for i in list(itertools.chain(*l))]
  return dict(zip(res_arr[::2], res_arr[1::2]))

class ValidationError(Exception):
    pass

class F5Aws(object):
  """
    This class is used to execute a set of ansible playbooks included in ./playbooks. 
    Playbooks are executed using the run_playbooks method, which reloads the 
    inventory between each playbook.  This is slightly different than the 
    way that ansible-playbook command typically handles things.  It only loads
    the inventory once for a set of playbooks.  
  """
  def __init__(self):
    try:
      # load settings stored in a file configured by user
      global_vars_path = '~/.{}'.format(__prog__)
      fd = open(os.path.expanduser(global_vars_path), 'r')
      self.settings = dict(yaml.load(fd))
    
      for v in REQUIRED_VARS:
        if self.settings.get(v, None) is None:
          raise Exception('Required variable "{}" not found in {}'.format(v, global_vars_path))

      self.settings['vars_path'] = os.path.expanduser('~/vars/{}'.format(__prog__))
      self.settings['env_path'] = self.settings['vars_path'] + '/env'
      self.settings['bin_path'] = self.settings['install_path'] + '/bin' 
      
      #make the /env/ directory if it does not exist
      os.makedirs(self.settings['env_path'])
    except OSError:
      pass

  def cmd_init(self, options, extra_vars):
    """
        To instantiate a new environment, we create a set
        of inventory files for that environment. 
        
        See individual playbooks for more info. 
    """
    playbooks = ['init.yml']

    # basic string checking to prevent failures later in playbook
    if not re.match('^[a-zA-z]{1}[a-zA-Z0-9-]*', options.env_name):
      raise ValidationError('The environment name must match the following regexp: "[a-zA-z]{1}[a-zA-Z0-9-]*" ')

    # check to make sure this inventory does not already exist
    print self.settings['env_path']
    if os.path.isdir((self.settings['env_path'] +'/'+ options.env_name)) and not options.force:
      raise ValidationError('There is already an environment with name "%s".  Use -f, --force to update the inventory variables for this environment. ' % options.env_name)

    # uses the inventory included in this repository 
    inventory = self.settings['install_path']+'/inventory/hosts'
    self.run_playbooks(playbooks, inventory, options, extra_vars)

  def cmd_deploy(self, options, extra_vars):
    """
        Deploy an environment based on the set of inventory files 
        created by the 'init' command.

        See individual playbooks for more info. 
    """
    playbooks = [
      'deploy_vpc_cft.yml',
      'deploy_az_cft.yml',
      'deploy_bigip_cft.yml',
      'deploy_gtm_cft.yml',
      'deploy_app_cft.yml',
      'deploy_client_cft.yml',
      'deploy_app.yml',
      'deploy_bigip.yml',
      'deploy_bigip_app1.yml',
      'deploy_bigip_app2.yml',
      'deploy_gtm.yml',
      'deploy_gtm_app1.yml',
      'deploy_gtm_app2.yml',
      'deploy_client.yml'
    ]

    # uses the inventory created in ~/vars/f5aws/env/<env name> created by `init`
    inventory = '%s/%s/inventory/hosts' % (self.settings['env_path'], options.env_name)
    self.run_playbooks(playbooks, inventory, options, extra_vars)

  def cmd_teardown(self, options, extra_vars):
    """
      Complete teardown a deployed environment.
      Does not remove the inventory files in ~/vars/f5aws/env/<env name>
    """
    playbooks = ['teardown_all.yml']
    
    inventory = '%s/%s/inventory/hosts' % (self.settings['env_path'], options.env_name)
    self.run_playbooks(playbooks, inventory, options, extra_vars)

  def cmd_remove(self, options, extra_vars):
    """
      Deletes all inventory files for a deployment from ~/vars/f5aws/env/<env name>
      This environment should already have been torn down using `teardown`
    """
    env = extra_vars['env_name']
    resources, statuses = self.get_env_status(env)
    
    okToRemove = True
    stillExist = []
    for r in resources: 
      if statuses[r]['state'] == 'deployed':
        okToRemove = False
        stillExist.append(r)

    if okToRemove is True:
      playbooks = ['remove.yml']

     # uses the inventory included in this repository 
      inventory = self.settings['install_path']+'/inventory/hosts'
      self.run_playbooks(playbooks, inventory, options, extra_vars)
    else:
      msg = """Cannot remove environment '%s' until all resources have been de-provisioned.
The following resources still exist: %s. 
Hint: try './bin/f5aws teardown %s'""" % (env, stillExist, env)

      display(msg, color='red', stderr=True)
        
  def cmd_list(self, options, extra_vars):
    """
      Implements a command line method to list all environments that have been instantiated using `init`.
    """
    display("Installed environments (%s):" %
      self.settings['env_path'], color='green', stderr=False) 
    envs = self.get_envs()
    if len(envs) == 0:
      display("(none)", color='red', stderr=False) 
    else:
      for env in self.get_envs():
        self.display_env_info(env)
        self.display_env_resources(env, False)
        
  def cmd_describe(self, options, extra_vars):
    """
      Implements command line method to provide more details on the resources associated with 
      a particular deployment (vpc, subnets, bigip, app hosts, etc...)
    """
    try:
      env = extra_vars['env_name']
      self.display_env_info(env)
      self.display_env_resources(env, True)
    except IOError:
      display(" Environment '%s' does not exist" % env, color='red', stderr=True)

  def cmd_start_traffic(self, options, extra_vars):
    """
      Implements command line method to pass traffic through BIG-IP
    """
    # uses the inventory created in ~/vars/f5aws/env/<env name> created by `init`
    inventory = '%s/%s/inventory/hosts' % (self.settings['env_path'], options.env_name)
    self.run_playbooks(['launch_traffic.yml'], inventory, options, extra_vars)

    print 'Jmeter now running on clienthost in zone1'

  def cmd_stop_traffic(self, options, extra_vars):
    """
      Implements command line method to stop jmeter client
    """
    # uses the inventory created in ~/vars/f5aws/env/<env name> created by `init`
    inventory = '%s/%s/inventory/hosts' % (self.settings['env_path'], options.env_name)
    self.run_playbooks(['stop_traffic.yml'], inventory, options, extra_vars)

  def run_playbooks(self, playbooks, inventory_path, options, extra_vars):
    """
      This is a modified version of the function used within ansible-playbook.
      playbooks 
    """
    # get the absolute path for the playbooks
    playbooks = ['{}/playbooks/{}'.format(self.settings['install_path'], pb) for pb in playbooks]

    # Ansible defaults carried over from `ansible-playbook`.  Changes these
    #  shouldn't be necessary since all R/W is done within *this* users directory. 
    sshpass = None
    sudopass = None
    su_pass = None
    vault_pass = None

    for playbook in playbooks:
      if not os.path.exists(playbook):
        raise errors.AnsibleError("the playbook: %s could not be found" % playbook)
      if not (os.path.isfile(playbook) or stat.S_ISFIFO(os.stat(playbook).st_mode)):
        raise errors.AnsibleError("the playbook: %s does not appear to be a file" % playbook)

    for playbook in playbooks:
      display("Running playbook: %s" % playbook, color='green', stderr=False)
      #display("Private Key is: %s" % options.private_key_file )

      stats = callbacks.AggregateStats()
      playbook_cb = callbacks.PlaybookCallbacks(verbose=utils.VERBOSITY)
      runner_cb = callbacks.PlaybookRunnerCallbacks(stats, verbose=utils.VERBOSITY)
      inventory = ansible.inventory.Inventory(inventory_path, vault_password=vault_pass)

      if len(inventory.list_hosts()) == 0:
          raise errors.AnsibleError("provided hosts list is empty")

      pb = ansible.playbook.PlayBook(
        playbook=playbook,
        module_path=options.module_path,
        inventory=inventory,
        forks=options.forks,
        remote_user=options.remote_user,
        remote_pass=sshpass,
        callbacks=playbook_cb,
        runner_callbacks=runner_cb,
        stats=stats,
        timeout=options.timeout,
        transport=options.connection,
        sudo=options.sudo,
        sudo_user=options.sudo_user,
        sudo_pass=sudopass,
        extra_vars=extra_vars,
        check=options.check,
        diff=options.diff,
        su=options.su,
        su_pass=su_pass,
        su_user=options.su_user,
        vault_password=vault_pass,
        force_handlers=options.force_handlers
      )

      if options.flush_cache:
        display(callbacks.banner("FLUSHING FACT CACHE"))
        pb.SETUP_CACHE.flush()

      if options.listhosts or options.listtasks or options.syntax:
        print ''
        print 'playbook: %s' % playbook
        print ''
        playnum = 0
        for (play_ds, play_basedir) in zip(pb.playbook, pb.play_basedirs):
          playnum += 1
          play = ansible.playbook.Play(pb, play_ds, play_basedir,
                                        vault_password=pb.vault_password)
          label = play.name
          hosts = pb.inventory.list_hosts(play.hosts)

          # Filter all tasks by given tags
          if pb.only_tags != 'all':
            if options.subset and not hosts:
              continue
            matched_tags, unmatched_tags = play.compare_tags(pb.only_tags)

            # Remove skipped tasks
            matched_tags = matched_tags - set(pb.skip_tags)

            unmatched_tags.discard('all')
            unknown_tags = ((set(pb.only_tags) | set(pb.skip_tags)) -
                            (matched_tags | unmatched_tags))

            if unknown_tags:
              continue

          if options.listhosts:
            print '  play #%d (%s): host count=%d' % (playnum, label, len(hosts))
            for host in hosts:
                print '    %s' % host

          if options.listtasks:
              print '  play #%d (%s):' % (playnum, label)

              for task in play.tasks():
                if (set(task.tags).intersection(pb.only_tags) and not
                  set(task.tags).intersection(pb.skip_tags)):
                  if getattr(task, 'name', None) is not None:
                    # meta tasks have no names
                    print '    %s' % task.name
          if options.listhosts or options.listtasks:
              print ''
        continue

      if options.syntax:
        # if we've not exited by now then we are fine.
        print 'Playbook Syntax is fine'
        return 0

      failed_hosts = []
      unreachable_hosts = []

      try:
        pb.run()

        hosts = sorted(pb.stats.processed.keys())
        display(callbacks.banner("PLAY RECAP"))
        playbook_cb.on_stats(pb.stats)

        for h in hosts:
          t = pb.stats.summarize(h)
          if t['failures'] > 0:
              failed_hosts.append(h)
          if t['unreachable'] > 0:
              unreachable_hosts.append(h)

        retries = failed_hosts + unreachable_hosts

        if len(retries) > 0:
          filename = pb.generate_retry_inventory(retries)
          if filename:
              display("           to retry, use: --limit @%s\n" % filename)

        for h in hosts:
          t = pb.stats.summarize(h)

          display("%s : %s %s %s %s" % (
            hostcolor(h, t),
            colorize('ok', t['ok'], 'green'),
            colorize('changed', t['changed'], 'yellow'),
            colorize('unreachable', t['unreachable'], 'red'),
            colorize('failed', t['failures'], 'red')),
            screen_only=True
          )

          display("%s : %s %s %s %s" % (
            hostcolor(h, t, False),
            colorize('ok', t['ok'], None),
            colorize('changed', t['changed'], None),
            colorize('unreachable', t['unreachable'], None),
            colorize('failed', t['failures'], None)),
            log_only=True
          )

        print ""
        if len(failed_hosts) > 0:
          return 2
        if len(unreachable_hosts) > 0:
          return 3

      except errors.AnsibleError, e:
        display("ERROR: %s" % e, color='red')
        return 1

    return 0

  def get_envs(self):
    """
      Gets a list of all deployments
    """
    return os.listdir(self.settings['env_path'])

  def display_env_info(self, env):
    """
    Print deployment variables to stdout
    """
    env_info = self.get_env_info(env)
    display(" - %s" % env, color='green', stderr=False)
    for k in sorted(env_info, key=lambda key: key):
      display("    %s: %s" % (k, env_info[k]), color='green', stderr=False)

  def display_env_resources(self, env, show_resource_vars):  
    """
      Print information nicely about deployment resources to stdout
    """
    resources, statuses = self.get_env_status(env, show_resource_vars)
    display("    resources: ", color='green', stderr=False)
    for r in resources:
      if statuses[r]['state'] != 'deployed':
        color='red'
      else: 
        color='green'

      if show_resource_vars:
        display("      %s:" % r, color=color, stderr=False)
        display("        %s" % json.dumps(statuses[r], indent=10), color=color, stderr=False)
      else:
        display("      %s: %s" % (r, statuses[r]), color=color, stderr=False)

  def get_env_info(self, env):
    """Read some information about this @env from the inventory/hosts 
        file.  We do this by parsing the [all:vars] section.
    """

    print 'get_env_info'

    env_info = {}
    # get variables and status information about a deployment
    # all of these details are stored the ansible hosts file 
    # It would be nice to use ConfigParser here, but the new
    #  line characters break it. 
    with open(self.settings['env_path']+'/'+env+'/inventory/hosts', 'r') as f:
      foundVars = False
      for l in f.read().split('\n'):
        if foundVars is False:
          if 'all:vars' in l:
            foundVars=True
        else:
          # break on the first blank line
          if l.rstrip().lstrip() == '':
            break
          else:
            result = re.match('^([a-z0-9_\-\.]+)=([a-z0-9_\-\.\/]+)', l)
            if result:
              env_info[result.group(1)] = result.group(2)

    # don't show the password in the output
    del env_info['env_name']
    env_info['bigip_rest_password'] = '********'

    return env_info

  def get_env_status(self, env, show_resource_vars=False):
    """ 
      Aggregates and prints the status for an environment
      and all resources deployed in aws
    """
    managers = self.get_managers(env)
    statuses = {}
    resources = []
    for m in managers:
      # for each resource, we will get the results from
      #  most recent manager execution for that resource
      resource_name = m[:-8]
      resources.append(resource_name)
      try:
        fname = '{}/{}/{}.yml'.format(self.settings['env_path'], env, m)
        with open(fname) as f:
          latest = yaml.load(f)
          statuses[resource_name] = getattr(self,
              'state_'+latest['invocation']['module_name'],
              self.raise_not_implemented)(latest, show_resource_vars)
      except Exception as e:
        statuses[resource_name] = {'state': 'not deployed'}

    return resources, statuses

  def get_managers(self, env ):
    """
      Returns an ordered list of all the 'managers'
      who report status via a yaml file i the ./<env>/ directory
      For example, vpc-manager
    """
    managers = []
    
    with open(self.settings['env_path']+'/'+env+'/inventory/hosts', 'r') as f:
      for l in f.readlines():
        rematch = re.match('^([a-z0-9/-]*-manager)$', l.rstrip().lstrip())
        if rematch:
          managers.append(rematch.group(1))

    #return the unique set
    managers = list(set(managers))
    managers.sort()
    return managers

  def state_cloudformation(self, latest_result, show_resource_vars):
    """
      Returns the status of executed ansible cloudformation tasls
      from captured output. 

      We need to deal with the case where the stack does not exist
      in a particular fashion for the command line `descibe` and 
      `list commands.
    """
    result = {}
    cf = convert_str(latest_result['invocation']['module_args'])
    # we need to handle 'present' and 'absent' situations differently
    if cf['state'] == 'present':
      result['stack_name'] = cf['stack_name']
      if show_resource_vars:
        result['resource_vars'] = latest_result['stack_outputs']
      if (latest_result['output'] == 'Stack CREATE complete' or
        latest_result['output'] == 'Stack is already up-to-date.'):
        result['state'] = 'deployed'
      else:
        result['state']='deploy-error'
    else: # state == 'absent'...
      if (latest_result.get('output','') == 'Stack Deleted' or
        'does not exist' in latest_result.get('msg','')):
        result['state'] = 'absent'
      else:
        result['state'] = 'teardown-error'

    return result

  def raise_not_implemented(*args, **kwargs):
    raise NotImplementedError()

  def run(self):
    """
      Define the various command line methods and arguments here. 
      For each command, implement a sub-parser. Later we will call
      the corrosponding method (e.g. init -> cmd_init) and pass the 
      corrosponding argument values. 
    """
    parser = argparse.ArgumentParser(prog='f5aws')
    parser.add_argument('-v', '--verbose', action='count', default=0,
      help='verbose mode (-vvv for more, -vvvv to enable connection debugging')
    subparsers = parser.add_subparsers(dest='cmd', help='sub-command help')
    
    parser_init = subparsers.add_parser('init',
      help='Create a new AWS deployment with F5 services.')
    parser_init.set_defaults(cmd='init')
    parser_init.add_argument('env_name',
      help='Name of the new environment to be created')
    parser_init.add_argument('-f', '--force', required=False,
      action='store_true', default=False,
      help="Use to update inventory variables for an existing environment")
    parser_init.add_argument('-e', '--extra-vars', required=True,
      dest="extra_vars", action="append",
      help="set additional variables as key=value or YAML/JSON", default=[])
    # TODO: cleanup the variable passing for extravars so we don't need to 
    #   pass the extra-vars argument -- allow users to pass variables directly
    
    parser_deploy = subparsers.add_parser('deploy',
      help='Deploy EC2 resource and application services based on inventory files created using `init`.')
    parser_deploy.add_argument('env_name', metavar='ENVIRONMENT',
      type=str, help='Name of environment to be deployed/updated')
    
    parser_teardown = subparsers.add_parser('teardown',
      help='De-provision all resources in AWS EC2 for an environment created using `init`.')
    parser_teardown.add_argument('env_name', metavar='ENVIRONMENT',
      type=str, help='Name of environment to be de-provisioned. ')

    parser_describe = subparsers.add_parser('describe',
      help='Show resource variables along with environment information.')
    parser_describe.add_argument('env_name', metavar='ENVIRONMENT',
      type=str, help='Name of environment to describe')
    
    parser_list = subparsers.add_parser('list',
      help='List all deployments and corrosponding resource statuses.')

    parser_remove = subparsers.add_parser('remove',
      help='Remove all inventory files for an environment created using `init`.')
    parser_remove.add_argument('env_name', metavar='ENVIRONMENT',
      type=str, help='Name of environment to be deleted')

    parser_start_traffic = subparsers.add_parser('start_traffic',
      help='Begins jmeter client on clienthost in a single availability zone')
    parser_start_traffic.add_argument('env_name', metavar='ENVIRONMENT',
      type=str, help='Name of environment to which jmeter client should run traffic')

    parser_stop_traffic = subparsers.add_parser('stop_traffic',
      help='Stops jmeter client ')
    parser_stop_traffic.add_argument('env_name', metavar='ENVIRONMENT',
      type=str, help='Name of environment')

    options = parser.parse_args()

    for i in range(options.verbose):
      print 'Incrementing debug to level %s' % i
      utils.increment_debug(False, False, False, False)

    # additional argument handling based on the command executed
    extra_vars = {}
    if options.cmd == 'init':
      for extra_vars_opt in options.extra_vars:
        if extra_vars_opt.startswith("@"):
          # Argument is a YAML file (JSON is a subset of YAML)
          extra_vars = utils.combine_vars(extra_vars,
            utils.parse_yaml_from_file(extra_vars_opt[1:],
              vault_password=vault_pass))
        elif extra_vars_opt and extra_vars_opt[0] in '[{':
          # Arguments as YAML
          extra_vars = utils.combine_vars(extra_vars,
            utils.parse_yaml(extra_vars_opt))
        else:
          # Arguments as Key-value
          extra_vars = utils.combine_vars(extra_vars,
            utils.parse_kv(extra_vars_opt))

    if getattr(options, 'env_name', None) is not None:
      extra_vars['env_name'] = options.env_name

    # pass along our project variables to ansible
    #  some playbooks will need access keys and passwords during runtime 
    for v in REQUIRED_VARS:
      extra_vars[v] = self.settings[v]

    # cloudformation templates will need just the key name, without any extension
    extra_vars['ssh_key_name'] = self.settings['ssh_key'].split('/')[-1].split('.')[0]

    # Since we have forked and modified ansible-playbook book
    #  we have copied over many of these default variables. 
    #  some of the options have been disabled due to unknown 
    #  dependency changes we may have introduced. 
    options.forks = constants.DEFAULT_FORKS
    options.module_path = constants.DEFAULT_MODULE_PATH
    options.remote_user = constants.DEFAULT_REMOTE_USER
    options.timeout = constants.DEFAULT_TIMEOUT
    options.connection = constants.DEFAULT_TRANSPORT
    options.sudo = constants.DEFAULT_SUDO
    options.sudo_user = None
    options.su = constants.DEFAULT_SU
    options.su_user = constants.DEFAULT_SU_USER
    options.check = False #TODO: can we make this work for some scenarios?
    options.diff = False #TODO: can we make this work for some scenarios?
    options.force_handlers = False
    options.flush_cache = False
    options.listhosts = False  #TODO: can we make this work for some scenarios?
    options.listtasks = False  #TODO: can we make this work for some scenarios?
    options.syntax = False  #TODO: can we make this work for some scenarios?

    # how about a common set of return values by all cmd functions
    try:
      getattr(self, 'cmd_'+options.cmd, self.raise_not_implemented)(options, extra_vars)
    except ValidationError as e: 
      display("Failed while processing input arguments: %s" % e, color='red', stderr=True)
    #except Exception as e:
    #  display("Caught an unhandle exception: %s" % e, color='red', stderr=True)

if __name__ == "__main__":
  display(" ", log_only=True)
  display(" ".join(sys.argv), log_only=True)
  display(" ", log_only=True)

  try:
    F5Aws().run()
  except errors.AnsibleError, e:
    display("ERROR: %s" % e, color='red', stderr=True)
    sys.exit(1)
  except KeyboardInterrupt, ke:
    display("ERROR: interrupted", color='red', stderr=True)
    sys.exit(1)
